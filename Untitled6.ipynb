{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpZUbmDi4_gm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import re\n",
        "import spacy\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, BaggingClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline as ImblearnPipeline\n",
        "import numpy as np\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import make_pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncNOagxO5DUB",
        "outputId": "16960673-f936-4b22-e47d-03354a6db46e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['anticipation' 'joy' 'anger' 'sadness' 'fear' 'optimism' 'disgust'\n",
            " 'surprise']\n",
            "                                                Text sentiment  \\\n",
            "0  @Logitech @apple @Google @Microsoft @Dell @Len...   neutral   \n",
            "1  @MK_habit_addict @official_stier @MortalKombat...   neutral   \n",
            "2  As @CRN celebrates its 40th anniversary, Bob F...  positive   \n",
            "3  @dell your customer service is horrible especi...  negative   \n",
            "4  @zacokalo @Dell @DellCares @Dell give the man ...   neutral   \n",
            "\n",
            "   sentiment_score       emotion  emotion_score  \\\n",
            "0         0.853283  anticipation       0.587121   \n",
            "1         0.519470           joy       0.886913   \n",
            "2         0.763791           joy       0.960347   \n",
            "3         0.954023         anger       0.983203   \n",
            "4         0.529170         anger       0.776124   \n",
            "\n",
            "                                      processed_text  \n",
            "0          qwerty modify programmer thing like br...  \n",
            "1       s get new      year old   triple price   ...  \n",
            "2     celebrate th anniversary   bob faletra     ...  \n",
            "3    customer service horrible especially agent s...  \n",
            "4                                            man pay  \n"
          ]
        }
      ],
      "source": [
        "csv_file_path = 'sentiment-emotion-labelled_Dell_tweets.csv'\n",
        "df = pd.read_csv(csv_file_path)\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "# Define a text preprocessing function\n",
        "def preprocess_text(text):\n",
        "    # Lowercase the text\n",
        "    text = text.lower()\n",
        "    # Remove usernames, hashtags, and URLs\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "    text = re.sub(r'#\\w+', '', text)\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    # Remove special characters and numbers\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Use SpaCy for tokenization and lemmatization, and remove stop words and punctuation\n",
        "    doc = nlp(text)\n",
        "    filtered_tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
        "    return ' '.join(filtered_tokens)\n",
        "df.drop(columns=['Unnamed: 0', 'Datetime', 'Tweet Id', 'Username'], axis=1, inplace=True)\n",
        "print(df['emotion'].unique())\n",
        "# Handle missing values\n",
        "df.dropna(subset=['Text', 'sentiment', 'emotion'], inplace=True)\n",
        "df['processed_text'] = df['Text'].apply(preprocess_text)\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "whf5XvMcKbKD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c15f93c5-7328-4fdb-a24b-53567f97aba9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        id                                               text  \\\n",
            "0  eew5j0j                                    That game hurt.   \n",
            "1  eemcysk   >sexuality shouldn’t be a grouping category I...   \n",
            "2  ed2mah1     You do right, if you don't care then fuck 'em!   \n",
            "3  eeibobj                                 Man I love reddit.   \n",
            "4  eda6yn6  [NAME] was nowhere near them, he was by the Fa...   \n",
            "\n",
            "   example_very_unclear  admiration  amusement  anger  annoyance  approval  \\\n",
            "0                 False           0          0      0          0         0   \n",
            "1                  True           0          0      0          0         0   \n",
            "2                 False           0          0      0          0         0   \n",
            "3                 False           0          0      0          0         0   \n",
            "4                 False           0          0      0          0         0   \n",
            "\n",
            "   caring  confusion  ...  nervousness  optimism  pride  realization  relief  \\\n",
            "0       0          0  ...            0         0      0            0       0   \n",
            "1       0          0  ...            0         0      0            0       0   \n",
            "2       0          0  ...            0         0      0            0       0   \n",
            "3       0          0  ...            0         0      0            0       0   \n",
            "4       0          0  ...            0         0      0            0       0   \n",
            "\n",
            "   remorse  sadness  surprise  neutral  \\\n",
            "0        0        1         0        0   \n",
            "1        0        0         0        0   \n",
            "2        0        0         0        1   \n",
            "3        0        0         0        0   \n",
            "4        0        0         0        1   \n",
            "\n",
            "                                      processed_text  \n",
            "0                                          game hurt  \n",
            "1    sexuality not group category make different ...  \n",
            "2                             right not care fuck em  \n",
            "3                                    man love reddit  \n",
            "4                                        near falcon  \n",
            "\n",
            "[5 rows x 32 columns]\n"
          ]
        }
      ],
      "source": [
        "def batch_preprocess(texts, batch_size=500):\n",
        "    preprocessed_texts = []\n",
        "    # Use n_process=-1 to use all available CPU cores for parallel processing\n",
        "    for doc in nlp.pipe(texts, batch_size=batch_size, n_process=-1):\n",
        "        filtered_tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
        "        preprocessed_texts.append(' '.join(filtered_tokens))\n",
        "    return preprocessed_texts\n",
        "df2 = pd.read_csv('go_emotions_dataset.csv')\n",
        "df2['processed_text'] = df2['text'].apply(preprocess_text)\n",
        "print(df2.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AAboCMpvLFjT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "251805f8-c032-42ab-f6d5-70d49d6c556a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                      processed_text mapped_emotion\n",
            "0       s get new      year old   triple price   ...            joy\n",
            "1     celebrate th anniversary   bob faletra     ...            joy\n",
            "2    customer service horrible especially agent s...          anger\n",
            "3                                            man pay          anger\n",
            "4  screenshot act website     latitude   laptop k...            sad\n"
          ]
        }
      ],
      "source": [
        "# Updated mapping to consolidate 'positive' into 'joy' and 'negative' into 'sad'\n",
        "emotion_cols = ['admiration', 'amusement',\n",
        "       'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity',\n",
        "       'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment',\n",
        "       'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love',\n",
        "       'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse',\n",
        "       'sadness', 'surprise', 'neutral'\n",
        "]\n",
        "df2['emotion'] = df2[emotion_cols].idxmax(axis=1)\n",
        "updated_emotion_mapping = {\n",
        "    'anger': 'anger',\n",
        "    'surprise': 'surprise',\n",
        "    'disgust': 'sad',  # Map to 'sad'\n",
        "    'joy': 'joy',\n",
        "    'sadness': 'sad',\n",
        "    'admiration': 'love',  # Map to 'joy'\n",
        "    'amusement': 'joy',  # Map to 'joy'\n",
        "    'annoyance': 'sad',  # Map to 'sad'\n",
        "    'approval': 'joy',  # Map to 'joy'\n",
        "    'caring': 'joy',  # Map to 'joy'\n",
        "    'confusion': 'neutral',\n",
        "    'curiosity': 'joy',  # Map to 'joy'\n",
        "    'desire': 'love',  # Map to 'joy'\n",
        "    'disappointment': 'sad',  # Map to 'sad'\n",
        "    'disapproval': 'sad',  # Map to 'sad'\n",
        "    'embarrassment': 'sad',  # Map to 'sad'\n",
        "    'excitement': 'joy',  # Map to 'joy'\n",
        "    'gratitude': 'joy',  # Map to 'joy'\n",
        "    'grief': 'sad',  # Map to 'sad'\n",
        "    'nervousness': 'fear',  # Map to 'sad'\n",
        "    'optimism': 'joy',  # Map to 'joy'\n",
        "    'pride': 'joy',  # Map to 'joy'\n",
        "    'realization': 'surprise',\n",
        "    'relief': 'joy',  # Map to 'joy'\n",
        "    'remorse': 'sad',  # Map to 'sad'\n",
        "    'neutral': 'neutral'  # Optional: remove if not needed\n",
        "}\n",
        "\n",
        "# Apply the updated mapping\n",
        "df['mapped_emotion'] = df['emotion'].map(updated_emotion_mapping).fillna('unmapped')\n",
        "df2['mapped_emotion'] = df2['emotion'].map(updated_emotion_mapping).fillna('unmapped')\n",
        "\n",
        "# Remove rows with 'unmapped' emotions\n",
        "df = df[df['mapped_emotion'] != 'unmapped']\n",
        "df2 = df2[df2['mapped_emotion'] != 'unmapped']\n",
        "# df.drop(columns=emotion_cols, axis=1, inplace=True)\n",
        "# Concatenate the two dataframes\n",
        "combined_df = pd.concat([\n",
        "    df[['processed_text', 'mapped_emotion']],\n",
        "    df2[['processed_text', 'mapped_emotion']]\n",
        "], ignore_index=True)\n",
        "\n",
        "# Check the first few rows of the combined dataframe\n",
        "print(combined_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xdvm68rFgJ0H",
        "outputId": "f2750715-f3c3-4e3f-aeda-568fd7cba760"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['processed_text', 'mapped_emotion'], dtype='object')\n",
            "<bound method NDFrame.head of                                            processed_text mapped_emotion\n",
            "0            s get new      year old   triple price   ...            joy\n",
            "1          celebrate th anniversary   bob faletra     ...            joy\n",
            "2         customer service horrible especially agent s...          anger\n",
            "3                                                 man pay          anger\n",
            "4       screenshot act website     latitude   laptop k...            sad\n",
            "...                                                   ...            ...\n",
            "242829          feel like unkind wrong think people close          anger\n",
            "242830   m feel little cranky negative doctor appointment          anger\n",
            "242831  feel useful people give great feeling achievement            joy\n",
            "242832     m feel comfortable derby feel start step shell            joy\n",
            "242833  feel weird meet w people text like not talk fa...           fear\n",
            "\n",
            "[242834 rows x 2 columns]>\n"
          ]
        }
      ],
      "source": [
        "file_path = '/content/val.txt'  # Update with the actual path to your text file\n",
        "\n",
        "# Read and parse the text file\n",
        "data = []\n",
        "with open(file_path, 'r') as file:\n",
        "    for line in file:\n",
        "        text, emotion = line.strip().split(';')\n",
        "        processed_text = preprocess_text(text)  # Apply preprocessing to the text\n",
        "        data.append({'processed_text': processed_text, 'mapped_emotion': emotion})\n",
        "new_data_df = pd.DataFrame(data)\n",
        "print(new_data_df.columns)\n",
        "# Concatenate this new DataFrame with the existing combined_df\n",
        "combined_df = pd.concat([combined_df, new_data_df], ignore_index=True)\n",
        "print(combined_df.head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hv6cXdy55Pjg",
        "outputId": "b9c8b8d5-69eb-4711-91d4-e8a16941f8e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN in features: False\n",
            "NaN in labels: False\n"
          ]
        }
      ],
      "source": [
        "X = combined_df['processed_text']\n",
        "y = combined_df['mapped_emotion']\n",
        "# Encode the labels numerically\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "print(\"NaN in features:\", X.isna().any())\n",
        "print(\"NaN in labels:\", pd.isna(y_encoded).any())\n",
        "\n",
        "# Remove rows with NaN values in features or labels\n",
        "combined_df = combined_df.dropna(subset=['processed_text', 'mapped_emotion'])\n",
        "\n",
        "# Update X and y_encoded after removing NaN values\n",
        "X = combined_df['processed_text']\n",
        "y_encoded = label_encoder.fit_transform(combined_df['mapped_emotion'])\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a pipeline with TfidfVectorizer and MultinomialNB\n",
        "pipeline = ImblearnPipeline([\n",
        "    ('vectorizer', TfidfVectorizer(max_df=0.5, ngram_range=(1, 3))),\n",
        "    ('sampling', SMOTE(random_state=42)),\n",
        "    ('classifier', RandomForestClassifier(class_weight='balanced', random_state=42))\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXUeRyy2-PHu",
        "outputId": "1b584cd9-1542-40c4-f1ba-dee977842fee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'vectorizer__ngram_range': (1, 2), 'vectorizer__max_df': 0.6, 'classifier__rf__n_estimators': 100, 'classifier__rf__max_depth': 15}\n",
            "Best Score: 0.7074991033012022\n"
          ]
        }
      ],
      "source": [
        "base_models = [\n",
        "    ('rf', RandomForestClassifier(class_weight='balanced', random_state=42)),\n",
        "    ('lr', LogisticRegression(max_iter=500, random_state=42))\n",
        "]\n",
        "final_estimator = LogisticRegression(max_iter=500, random_state=42)\n",
        "stacking_clf = StackingClassifier(estimators=base_models, final_estimator=final_estimator, cv=3, n_jobs=-1)\n",
        "\n",
        "# Create a pipeline with the StackingClassifier\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer()),\n",
        "    ('classifier', stacking_clf)\n",
        "])\n",
        "\n",
        "# Adjusted parameter grid for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'vectorizer__max_df': np.linspace(0.4, 0.7, 4),\n",
        "    'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
        "    'classifier__rf__n_estimators': [50, 100],  # Specify RandomForest parameters\n",
        "    'classifier__rf__max_depth': [10, 15]\n",
        "}\n",
        "\n",
        "# Create a RandomizedSearchCV object\n",
        "random_search = RandomizedSearchCV(\n",
        "    pipeline,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=8,\n",
        "    cv=3,\n",
        "    verbose=1,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Perform hyperparameter tuning on a subset of data\n",
        "subset_size = 2000  # Adjust as needed\n",
        "X_subset = X[:subset_size]\n",
        "y_subset = y[:subset_size]\n",
        "\n",
        "random_search.fit(X_subset, y_subset)\n",
        "\n",
        "# Output the best parameters and score\n",
        "best_parameters = random_search.best_params_\n",
        "best_score = random_search.best_score_\n",
        "print(\"Best Parameters:\", best_parameters)\n",
        "print(\"Best Score:\", best_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NV-le7Jw5ZnO",
        "outputId": "2823109e-d783-41f8-b275-c97f5980f52b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.66      0.52      0.58      3617\n",
            "        fear       0.78      0.57      0.66       646\n",
            "         joy       0.58      0.66      0.62     15274\n",
            "        love       0.59      0.34      0.43      5039\n",
            "     neutral       0.48      0.60      0.53     12433\n",
            "         sad       0.49      0.45      0.47      8564\n",
            "     sadness       0.77      0.82      0.80      1126\n",
            "    surprise       0.42      0.13      0.20      1868\n",
            "\n",
            "    accuracy                           0.54     48567\n",
            "   macro avg       0.60      0.51      0.54     48567\n",
            "weighted avg       0.55      0.54      0.54     48567\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create the base models for the StackingClassifier with the tuned parameters\n",
        "base_models = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, max_depth=15, class_weight='balanced', random_state=42)),\n",
        "    ('lr', LogisticRegression(max_iter=500, random_state=42))  # Logistic Regression as another base model\n",
        "]\n",
        "\n",
        "# Final estimator for the StackingClassifier\n",
        "final_estimator = LogisticRegression(max_iter=500, random_state=42)\n",
        "\n",
        "# Create the StackingClassifier\n",
        "stacking_clf = StackingClassifier(estimators=base_models, final_estimator=final_estimator, cv=3, n_jobs=-1)\n",
        "\n",
        "# Create a pipeline with TfidfVectorizer and the StackingClassifier\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer(max_df=0.6, ngram_range=(1, 2))),\n",
        "    ('classifier', stacking_clf)\n",
        "])\n",
        "\n",
        "# Assuming X and y are your dataset features and labels\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert all labels to string type\n",
        "y_train_str = y_train.astype(str)\n",
        "y_test_str = y_test.astype(str)\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train_str)\n",
        "\n",
        "# Train the pipeline with the training data\n",
        "pipeline.fit(X_train, y_train_encoded)\n",
        "\n",
        "# Prepare target names for the classification report\n",
        "target_names = label_encoder.classes_\n",
        "\n",
        "# Evaluate the pipeline on the test data\n",
        "y_pred = pipeline.predict(X_test)\n",
        "y_test_encoded = label_encoder.transform(y_test_str)\n",
        "report = classification_report(y_test_encoded, y_pred, target_names=target_names)\n",
        "\n",
        "# Print the classification report\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePbcS6awV8-W",
        "outputId": "f05f3d59-3e2f-45e5-bbac-d11b3ab7b0c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your feelings of joy are valid.\n"
          ]
        }
      ],
      "source": [
        "# New text to analyze\n",
        "# new_text = \"We bought this for our nieces birthday. She loved it! Thank you so much. We will definitely shop with this vender in the future! Fast shipping. Just as described. Would recommend highly.\"\n",
        "new_text = \"I ordered my coffee, like i have at least 5 or 6 other times this year. When it arrived it was in a bag, not the normal shipping box that it usually comes in. When I opened it, immediately, coffee grounds fell out of bag. Upon further inspection, all the boxes in the bag are damaged, and not one of them has undamaged K-cups. I love the coffee, regular drinker, but a good portion of this delivery is destroyed or highly damaged.\"\n",
        "# Preprocess the text (make sure this matches the preprocessing used during training)\n",
        "# For example, if you used certain tokenization or cleaning steps, apply them here\n",
        "# Since this is an example, I'm directly using the text as is\n",
        "\n",
        "# Use the trained pipeline to predict the emotion\n",
        "predicted_emotion = pipeline.predict([new_text])[0]\n",
        "\n",
        "# Get the emotion label from the encoded prediction\n",
        "emotion_label = label_encoder.inverse_transform([predicted_emotion])[0]\n",
        "\n",
        "# Format and print the output statement\n",
        "print(f\"Your feelings of {emotion_label} are valid.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}